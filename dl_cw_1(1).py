# -*- coding: utf-8 -*-
"""dl_cw_1(1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11nmceHgcs3yd-OrXYKDr3nrLgDNH_1tP

# Coursework1: Convolutional Neural Networks 
### Autograding
Part 1 of this coursework is autograded. This notebook comes with embedded tests which will verify that your implementations provide outputs with the appropriate types and shapes required for our hidden tests. You can run these same public tests through [LabTS](https://teaching.doc.ic.ac.uk/labts) when you have finished your work, to check that we get the same results when running these public tests.

Hidden tests will be ran after the submission deadline, and cannot be accessed :)

### Setting up working environment 

For this coursework you will need to train a large network, therefore we recommend you work with Google Colaboratory or Paperspace, where you can access GPUs. 

#### Paperspace
See [the Paperspace information doc](https://hackmd.io/@afspies/S1stL8Qnt). 

The public tests are embedded within the notebook and you can ignore the **tests** folder

#### Google Colab
To run this notebook on Google Colab, please log in to your account and go to the following page: https://colab.research.google.com. Then upload this notebook.

For GPU support, go to "Edit" -> "Notebook Settings", and select "Hardware accelerator" as "GPU".

**To run the public tests within colab** you will need to copy the "tests" folder to the ```/content/``` directory (this is the default working directory - you can also change directories with ```%cd```)

#### Setup
You will need to install pytorch and other libraries by running the following cell:
"""

#!pip install -q otter-grader pandoc torch torchvision sklearn seaborn

# Initialization Cell
#import otter
#grader = otter.Notebook("dl_cw_1.ipynb")
import matplotlib.pyplot as plt # DO NOT use %matplotlib inline in the notebook
import numpy as np
rng_seed = 90

ON_COLAB = False

#!wget https://zenodo.org/record/5846979/files/NaturalImageNetTest.zip?download=1
# !wget https://zenodo.org/record/5846979/files/NaturalImageNetTrain.zip?download=1
#if ON_COLAB:
#    !unzip /content/NaturalImageNetTest.zip?download=1 > /dev/null
    # !unzip /content/NaturalImageNetTrain.zip?download=1 > /dev/null
#else: 
#    !unzip NaturalImageNetTest.zip?download=1 > /dev/null
#    !unzip NaturalImageNetTrain.zip?download=1 > /dev/null

#torch
import torch
from torch.nn import Conv2d, MaxPool2d, Dropout
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torch.utils.data import sampler
from torchvision import datasets, transforms
from torchvision.utils import save_image, make_grid
#other
import matplotlib.pyplot as plt
import numpy as np
import argparse
# set the seed for reproducibility
rng_seed = 90
torch.manual_seed(rng_seed)

class Args():
    def __init__(self, apply_augmentation=False, lr=0.0001, dropout=False, hidden_layers=6, base_hidden_size=16, batch_size=128):
        self.apply_augmentation = apply_augmentation
        self.lr = lr
        self.dropout = dropout
        self.hidden_layers = hidden_layers
        self.base_hidden_size = base_hidden_size
        self.batch_size = batch_size

def define_parser():
    p = argparse.ArgumentParser()
    p.add_argument('-a', '--aug', type=bool, default=False, help='Apply augmentation or nah')
    p.add_argument('-l', '--lr', type=float, default=0.0001, help='Learning rate for optimiser')
    p.add_argument('-d', '--dropout', type=bool, default=False, help='Add dropout layers to network')
    p.add_argument('-n', '--hidden_layers', type=int, default=6, help='Number of hidden layers in network')
    p.add_argument('-s', '--hidden_size', type=int, default=16, help='Base hidden size to use in layers')
    p.add_argument('-b', '--batch_size', type=int, default=128, help='Batch size')
    return p

parser = define_parser()
a = parser.parse_args()

args = Args(apply_augmentation=a.aug, lr=a.lr, dropout=a.dropout, hidden_layers=a.hidden_layers, base_hidden_size=a.hidden_size, batch_size=a.batch_size)
# args = Args()

mean = torch.Tensor([0.485, 0.456, 0.406])
std = torch.Tensor([0.229, 0.224, 0.225])


data_augs = transforms.Compose([
    # transforms.ToPILImage('RGB'),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(20),
    transforms.ColorJitter(brightness=0.4, contrast=0.3, saturation=0.1, hue=0),
    # transforms.ToTensor(),
    # transforms.Normalize(mean.tolist(), std.tolist()),
])

class ImageLoaderAugment(Dataset):
    def __init__(self, image_list, transforms=None):
        self.image_list = image_list
        self.transforms = transforms
    
    def __len__(self):
        return (len(self.image_list))

    def __getitem__(self, i):
        image, label = self.image_list[i] #??
        if self.transforms is not None:
            for t in self.transforms:
                image = t(image)
        return image, label

# When we import the images we want to first convert them to a tensor. 
# It is also common in deep learning to normalise the the inputs. This 
# helps with stability.
# To read more about this subject this article is a great one:
# https://towardsdatascience.com/understand-data-normalization-in-machine-learning-8ff3062101f0

# transforms is a useful pytorch package which contains a range of functions
# for preprocessing data, for example applying data augmentation to images 
# (random rotations, blurring the image, randomly cropping the image). To find out
# more please refer to the pytorch documentation:
# https://pytorch.org/docs/stable/torchvision/transforms.html

# mean = torch.Tensor([0.485, 0.456, 0.406])
# std = torch.Tensor([0.229, 0.224, 0.225])
transform = transforms.Compose(
        [
            transforms.Resize(256),
            transforms.CenterCrop(256),
            transforms.ToTensor(),
            transforms.Normalize(mean.tolist(), std.tolist()),
        ]
    )
train_path = ('/content/' if ON_COLAB else '') + 'NaturalImageNetTrain'
test_path = ('/content/' if ON_COLAB else '') +'NaturalImageNetTest'

train_dataset = datasets.ImageFolder(train_path)#, transform=transform)
test_dataset = datasets.ImageFolder(test_path, transform=transform)

# Create train val split
n = len(train_dataset)
n_val = int(n/10)

train_set, val_set = torch.utils.data.random_split(train_dataset, [n-n_val, n_val])

print(len(train_set), len(val_set), len(test_dataset))

# The number of images to process in one go. If you run out of GPU
# memory reduce this number! 
batch_size = args.batch_size

data_augs = transforms.Compose([
    # transforms.ToPILImage('RGB'),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(20),
    transforms.ColorJitter(brightness=0.4, contrast=0.3, saturation=0.1, hue=0),
    # transforms.ToTensor(),
    # transforms.Normalize(mean.tolist(), std.tolist()),
])


# Dataloaders are a great pytorch functionality for feeding data into our AI models.
# see https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader
# for more info.

transforms_to_apply = [transform]
if args.apply_augmentation:
    transforms_to_apply.insert(0, data_augs)

aug_train_set = ImageLoaderAugment(train_set, transforms_to_apply)

aug_val_set = ImageLoaderAugment(val_set, [transform])

# loader_train = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)
loader_train = DataLoader(aug_train_set, batch_size=batch_size, shuffle=True, num_workers=2)

loader_val = DataLoader(aug_val_set, batch_size=batch_size, shuffle=True, num_workers=2)
loader_test = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=2)

unnormalize = transforms.Normalize((-mean / std).tolist(), (1.0 / std).tolist())

def denorm(x):
    '''
    Function to reverse the normalization so that we can visualise the outputs
    '''
    x = unnormalize(x)
    x = x.view(x.size(0), 3, 256, 256)
    return x

def show(img):
    '''
    function to visualise tensors
    '''
    if torch.cuda.is_available():
        img = img.cpu()
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1,2,0)).clip(0, 1))

"""**Visualising some example images** """

sample_inputs, _ = next(iter(loader_val))
fixed_input = sample_inputs[:27, :, :, :]

img = make_grid(denorm(fixed_input), nrow=9, padding=2, normalize=False,
                value_range=None, scale_each=False, pad_value=0)
plt.figure(figsize=(20,10))
plt.axis('off')
show(img)

"""Next, we define ResNet-18:"""

# define resnet building blocks

class ResidualBlock(nn.Module): 
    def __init__(self, inchannel, outchannel, stride=1, dropout=False): 
        
        super(ResidualBlock, self).__init__()

        self.dropout = dropout
        
        self.left = nn.Sequential(Conv2d(inchannel, outchannel, kernel_size=3, 
                                         stride=stride, padding=1, bias=False), 
                                  nn.BatchNorm2d(outchannel), 
                                  nn.ReLU(inplace=True),
                                  Conv2d(outchannel, outchannel, kernel_size=3, 
                                         stride=1, padding=1, bias=False), 
                                  nn.BatchNorm2d(outchannel)) 
        
        self.shortcut = nn.Sequential() 
        
        if stride != 1 or inchannel != outchannel: 
            
            self.shortcut = nn.Sequential(Conv2d(inchannel, outchannel, 
                                                 kernel_size=1, stride=stride, 
                                                 padding = 0, bias=False), 
                                          nn.BatchNorm2d(outchannel) ) 
            
    def forward(self, x): 
        
        out = self.left(x) 

        if self.dropout:
            out = Dropout(0.2)(x)
        
        out += self.shortcut(x) 
        
        out = F.relu(out) 
        
        return out


    
# define resnet

class ResNet(nn.Module):
    
    def __init__(self, ResidualBlock, num_classes = 20):
        
        super(ResNet, self).__init__()
        
        self.inchannel = 16

        all_layers = []

        all_layers.append(nn.Sequential(Conv2d(3, 16, kernel_size = 3, stride = 1,
                                            padding = 1, bias = False), 
                                  nn.BatchNorm2d(16), 
                                  nn.ReLU()))

        for i in range(args.hidden_layers):
            all_layers.append(self.make_layer(ResidualBlock, args.base_hidden_size * (2**i), 2, stride=2, dropout=args.dropout))
        
        # self.layer1 = self.make_layer(ResidualBlock, 16, 2, stride = 2)
        # self.layer2 = self.make_layer(ResidualBlock, 32, 2, stride = 2)
        # self.layer3 = self.make_layer(ResidualBlock, 64, 2, stride = 2)
        # self.layer4 = self.make_layer(ResidualBlock, 128, 2, stride = 2)
        # self.layer5 = self.make_layer(ResidualBlock, 256, 2, stride = 2)
        # self.layer6 = self.make_layer(ResidualBlock, 512, 2, stride = 2)


        all_layers.append(MaxPool2d(4))

        self.all_layers = nn.Sequential(*all_layers)
        self.fc = nn.Linear(512, num_classes)
        
    
    def make_layer(self, block, channels, num_blocks, stride, dropout=False):
        
        strides = [stride] + [1] * (num_blocks - 1)
        
        layers = []
        
        for stride in strides:
            
            layers.append(block(self.inchannel, channels, stride, dropout))
            
            self.inchannel = channels
            
        return nn.Sequential(*layers)
    
    
    def forward(self, x):
        
        # x = self.conv1(x)
        # x = self.layer1(x)
        # x = self.layer2(x)
        # x = self.layer3(x)
        # x = self.layer4(x)
        # x = self.layer5(x)
        # x = self.layer6(x)
        # x = self.maxpool(x)
        x = self.all_layers(x)
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        return x
    
# please do not change the name of this class
def MyResNet():
    return ResNet(ResidualBlock)

from sklearn.metrics import confusion_matrix
import seaborn as sns


def confusion(preds, y):
  labels = ['African Elephant', 'Kingfisher', 'Deer','Brown Bear', 'Chameleon', 'Dragonfly',
    'Giant Panda', 'Gorilla', 'Hawk', 'King Penguin', 'Koala', 'Ladybug', 'Lion',
    'Meerkat', 'Orangutan', 'Peacock', 'Red Fox', 'Snail', 'Tiger', 'White Rhino']
  # Plotting the confusion matrix
  cm = confusion_matrix(y.cpu().numpy(), preds.cpu().numpy(), normalize='true')
  fig, ax= plt.subplots(1, 1, figsize=(15,10))
  sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells

  # labels, title and ticks
  ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); 
  ax.set_title('Confusion Matrix');
  ax.xaxis.set_ticklabels(labels, rotation = 70); ax.yaxis.set_ticklabels(labels, rotation=0);
  plt.show()

def incorrect_preds(preds, y, test_img):
  labels = ['African Elephant', 'Kingfisher', 'Deer','Brown Bear', 'Chameleon', 'Dragonfly',
    'Giant Panda', 'Gorilla', 'Hawk', 'King Penguin', 'Koala', 'Ladybug', 'Lion',
    'Meerkat', 'Orangutan', 'Peacock', 'Red Fox', 'Snail', 'Tiger', 'White Rhino']
  # lets see a sample of the images which were classified incorrectly!
  correct = (preds == y).float()
  test_labels_check = correct.cpu().numpy()
  incorrect_indexes = np.where(test_labels_check == 0)

  test_img = test_img.cpu()
  samples = make_grid(denorm(test_img[incorrect_indexes][:9]), nrow=3,
                      padding=2, normalize=False, value_range=None, 
                      scale_each=False, pad_value=0)
  plt.figure(figsize = (20,10))
  plt.title('Incorrectly Classified Instances')
  show(samples)
  labels = np.asarray(labels)
  print('Predicted label',labels[preds[incorrect_indexes].cpu().numpy()[:9]])
  print('True label', labels[y[incorrect_indexes].cpu().numpy()[:9]])
  print('Corresponding images are shown below')

import matplotlib.pyplot as plt

def graph_curve(trainxs, trainys, valxs, valys, model):
  fig = plt.figure()
  test_acc = check_accuracy(loader_test, model, analysis=True)
  plt.plot(trainys, trainxs, label='Train data')
  plt.plot(valys, valxs, label='Validation data')
  title = 'Use data augmentation = %s\nLearning rate = %f\nUse dropout = %s\nNumber of hidden layers = %d\nBase size of hidden layers = %d\nBatch size = %d\nFinal test accuracy = %.3f'%(args.apply_augmentation, args.lr, args.dropout, args.hidden_layers, args.base_hidden_size, args.batch_size, test_acc)
  plt.title(title)
  plt.xlabel('Training step')
  plt.ylabel('Accuracy')
  plt.legend()
  fig.savefig("images/aug=%s_lr=%f_dropout=%s_hidden=%d_hsize=%d_batch=%d_acc=%.3f.png" % (args.apply_augmentation, args.lr, args.dropout, args.hidden_layers, args.base_hidden_size, args.batch_size, test_acc), bbox_inches = 'tight')
  plt.show()

USE_GPU = True
dtype = torch.float32 


if USE_GPU and torch.cuda.is_available():
    device = torch.device('cuda:0')
else:
    device = torch.device('cpu')

print(device)
    

print_every = 10
def check_accuracy(loader, model, analysis=False):
    # function for test accuracy on validation and test set
    
    num_correct = 0
    num_samples = 0
    model.eval()  # set model to evaluation mode
    with torch.no_grad():
        for t, (x, y) in enumerate(loader):
            x = x.to(device=device, dtype=dtype)  # move to device
            y = y.to(device=device, dtype=torch.long)
            scores = model(x)
            _, preds = scores.max(1)
            num_correct += (preds == y).sum()
            num_samples += preds.size(0)
            if t == 0 and analysis:
              stack_labels = y
              stack_predicts = preds
            elif analysis:
              stack_labels = torch.cat([stack_labels, y], 0)
              stack_predicts = torch.cat([stack_predicts, preds], 0)
        acc = float(num_correct) / num_samples
        print('Got %d / %d correct of val set (%.2f)' % (num_correct, num_samples, 100 * acc))
        if analysis:
          print('check acc', type(stack_predicts), type(stack_labels))
          confusion(stack_predicts, stack_labels)
          incorrect_preds(preds, y, x)
        return float(acc)

        

def train_part(model, optimizer, epochs=1):
    trainxs = []
    trainys = []
    valxs = []
    valys = []
    num_correct=0
    num_samples=0
    steps=0
    """
    Train a model on NaturalImageNet using the PyTorch Module API.
    
    Inputs:
    - model: A PyTorch Module giving the model to train.
    - optimizer: An Optimizer object we will use to train the model
    - epochs: (Optional) A Python integer giving the number of epochs to train for
    
    Returns: Nothing, but prints model accuracies during training.
    """
    model = model.to(device=device)  # move the model parameters to CPU/GPU
    for e in range(epochs):
        for t, (x, y) in enumerate(loader_train):
            steps += 1
            model.train()  # put model to training mode
            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU
            y = y.to(device=device, dtype=torch.long)

            scores = model(x)
            loss = F.cross_entropy(scores, y)

             # get train accuracy
            _, preds = scores.max(1)
            num_correct += (preds == y).sum()
            num_samples += preds.size(0)

            # Zero out all of the gradients for the variables which the optimizer
            # will update.
            optimizer.zero_grad()

            loss.backward()

            # Update the parameters of the model using the gradients
            optimizer.step()

            if t % print_every == 0:
                trainxs.append(float(num_correct) / num_samples)
                trainys.append(steps)
                #print('Epoch: %d, Iteration %d, loss = %.4f' % (e, t, loss.item()))
                num_correct=0
                num_samples=0
        val_acc = check_accuracy(loader_val, model)
        valxs.append(val_acc)
        valys.append(steps)
    graph_curve(trainxs, trainys, valxs, valys, model)

# define and train the network
model = MyResNet()
optimizer = optim.Adamax(model.parameters(), lr=args.lr, weight_decay=1e-7) 

params = sum(p.numel() for p in model.parameters() if p.requires_grad)
print("Total number of parameters is: {}".format(params))

train_part(model, optimizer, epochs = 10)


# report test set accuracy
check_accuracy(loader_val, model, analysis=True)


# save the model
torch.save(model.state_dict(), 'model.pt')


